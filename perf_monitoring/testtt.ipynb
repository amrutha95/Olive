{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/.conda/envs/emmanuel-onnx/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-29 00:10:57,266] [DEBUG] [engine.py:577:resolve_goals] Resolving goals: {'accuracy': {'accuracy': None}, 'latency': {'avg': None}}\n",
      "[2023-06-29 00:10:57,267] [DEBUG] [engine.py:596:resolve_goals] No baseline got as no goal is provided the the goal is threshold\n",
      "[2023-06-29 00:10:57,277] [DEBUG] [engine.py:498:run_search] Step 1 with search point {'OnnxConversion': {}, 'OrtTransformersOptimization': {}, 'OnnxQuantization': {'quant_mode': 'static', 'calibrate_method': 'MinMax', 'quant_format': 'QOperator', 'MatMulConstBOnly': False, 'weight_type': 'QUInt8', 'activation_type': 'QUInt8', 'per_channel': False, 'reduce_range': False, 'optimize_model': True, 'quant_preprocess': True}, 'OrtPerfTuning': {}} ...\n",
      "[2023-06-29 00:10:57,277] [INFO] [engine.py:837:_run_pass] Running pass OnnxConversion\n",
      "[2023-06-29 00:10:57,278] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:10:57,279] [DEBUG] [__init__.py:582:get_dummy_inputs] Using hf_config.dataset to get dummy inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/.conda/envs/emmanuel-onnx/lib/python3.8/site-packages/optuna/samplers/_tpe/sampler.py:278: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/home/emmanuel/.conda/envs/emmanuel-onnx/lib/python3.8/site-packages/optuna/samplers/_tpe/sampler.py:289: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-29 00:10:57,717] [DEBUG] [conversion.py:73:_run_for_config] Using hf config to get io_config for the model.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[2023-06-29 00:11:06,068] [INFO] [engine.py:837:_run_pass] Running pass OrtTransformersOptimization\n",
      "[2023-06-29 00:11:06,070] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:11:24,090] [INFO] [engine.py:837:_run_pass] Running pass OnnxQuantization\n",
      "[2023-06-29 00:11:24,094] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:11:24,095] [INFO] [quantization.py:333:_run_for_config] Preprocessing model for quantization\n",
      "[2023-06-29 00:12:08,588] [INFO] [engine.py:837:_run_pass] Running pass OrtPerfTuning\n",
      "[2023-06-29 00:12:08,592] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:12:10,386] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 0), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:12:22,750] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 1), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:12:44,367] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 208.2179\n",
      "[2023-06-29 00:12:44,369] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 34.99482\n",
      "[2023-06-29 00:12:44,369] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 39.99097\n",
      "[2023-06-29 00:12:44,370] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 35.78461\n",
      "[2023-06-29 00:12:44,370] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 27.77902\n",
      "[2023-06-29 00:12:44,370] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 37.60358\n",
      "[2023-06-29 00:12:44,371] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 37.29312\n",
      "[2023-06-29 00:12:44,371] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 37.40254\n",
      "[2023-06-29 00:12:44,372] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 31.82336\n",
      "[2023-06-29 00:12:44,372] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 205.92308\n",
      "[2023-06-29 00:12:44,372] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 30.58837\n",
      "[2023-06-29 00:12:44,373] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 39.44375\n",
      "[2023-06-29 00:12:44,373] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 31.32929\n",
      "[2023-06-29 00:12:44,373] [INFO] [perf_tuning.py:115:tune_onnx_model] Best result: {'test_name': \"execution_provider_[('CPUExecutionProvider', {})]_session_options_{'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': None}__io_bind_False\", 'execution_provider': [('CPUExecutionProvider', {})], 'session_options': {'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': None}, 'io_bind': False, 'latency_ms': 27.77902}\n",
      "[2023-06-29 00:12:44,376] [DEBUG] [engine.py:964:_evaluate_model] Evaluating model ...\n",
      "[2023-06-29 00:12:44,377] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:12:58,223] [DEBUG] [engine.py:819:_run_passes] Signal: {'accuracy-accuracy': 0.8357843137254902, 'latency-avg': 28.00311}\n",
      "[2023-06-29 00:12:58,228] [DEBUG] [engine.py:498:run_search] Step 2 with search point {'OnnxConversion': {}, 'OrtTransformersOptimization': {}, 'OnnxQuantization': {'quant_mode': 'dynamic', 'calibrate_method': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'quant_format': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'MatMulConstBOnly': True, 'weight_type': 'QUInt8', 'activation_type': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'per_channel': True, 'reduce_range': True, 'optimize_model': True, 'quant_preprocess': True}, 'OrtPerfTuning': {}} ...\n",
      "[2023-06-29 00:12:58,228] [INFO] [engine.py:837:_run_pass] Running pass OnnxConversion\n",
      "[2023-06-29 00:12:58,230] [DEBUG] [engine.py:845:_run_pass] Loading model from cache ...\n",
      "[2023-06-29 00:12:58,233] [INFO] [engine.py:837:_run_pass] Running pass OrtTransformersOptimization\n",
      "[2023-06-29 00:12:58,235] [DEBUG] [engine.py:845:_run_pass] Loading model from cache ...\n",
      "[2023-06-29 00:12:58,237] [INFO] [engine.py:837:_run_pass] Running pass OnnxQuantization\n",
      "[2023-06-29 00:12:58,241] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:12:58,244] [INFO] [quantization.py:336:_run_for_config] Already processed model for quantization, skipping preprocessing\n",
      "[2023-06-29 00:13:29,778] [INFO] [engine.py:837:_run_pass] Running pass OrtPerfTuning\n",
      "[2023-06-29 00:13:29,782] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:13:31,522] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 0), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:13:42,631] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 1), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:14:01,500] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 205.27577\n",
      "[2023-06-29 00:14:01,501] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 29.17117\n",
      "[2023-06-29 00:14:01,502] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 37.52153\n",
      "[2023-06-29 00:14:01,502] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 28.28242\n",
      "[2023-06-29 00:14:01,503] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 25.07949\n",
      "[2023-06-29 00:14:01,503] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 38.26937\n",
      "[2023-06-29 00:14:01,504] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 37.00565\n",
      "[2023-06-29 00:14:01,504] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 35.17373\n",
      "[2023-06-29 00:14:01,504] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 30.54845\n",
      "[2023-06-29 00:14:01,505] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 202.92866\n",
      "[2023-06-29 00:14:01,505] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 26.6119\n",
      "[2023-06-29 00:14:01,506] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 38.80204\n",
      "[2023-06-29 00:14:01,506] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 29.87976\n",
      "[2023-06-29 00:14:01,507] [INFO] [perf_tuning.py:115:tune_onnx_model] Best result: {'test_name': \"execution_provider_[('CPUExecutionProvider', {})]_session_options_{'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': None}__io_bind_False\", 'execution_provider': [('CPUExecutionProvider', {})], 'session_options': {'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': None}, 'io_bind': False, 'latency_ms': 25.07949}\n",
      "[2023-06-29 00:14:01,509] [DEBUG] [engine.py:964:_evaluate_model] Evaluating model ...\n",
      "[2023-06-29 00:14:01,510] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:14:15,862] [DEBUG] [engine.py:819:_run_passes] Signal: {'accuracy-accuracy': 0.8455882352941176, 'latency-avg': 24.17589}\n",
      "[2023-06-29 00:14:15,867] [DEBUG] [engine.py:498:run_search] Step 3 with search point {'OnnxConversion': {}, 'OrtTransformersOptimization': {}, 'OnnxQuantization': {'quant_mode': 'dynamic', 'calibrate_method': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'quant_format': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'MatMulConstBOnly': True, 'weight_type': 'QInt8', 'activation_type': <SpecialParamValue.IGNORED: 'OLIVE_IGNORED_PARAM_VALUE'>, 'per_channel': True, 'reduce_range': True, 'optimize_model': False, 'quant_preprocess': True}, 'OrtPerfTuning': {}} ...\n",
      "[2023-06-29 00:14:15,867] [INFO] [engine.py:837:_run_pass] Running pass OnnxConversion\n",
      "[2023-06-29 00:14:15,868] [DEBUG] [engine.py:845:_run_pass] Loading model from cache ...\n",
      "[2023-06-29 00:14:15,871] [INFO] [engine.py:837:_run_pass] Running pass OrtTransformersOptimization\n",
      "[2023-06-29 00:14:15,872] [DEBUG] [engine.py:845:_run_pass] Loading model from cache ...\n",
      "[2023-06-29 00:14:15,875] [INFO] [engine.py:837:_run_pass] Running pass OnnxQuantization\n",
      "[2023-06-29 00:14:15,878] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:14:15,880] [INFO] [quantization.py:336:_run_for_config] Already processed model for quantization, skipping preprocessing\n",
      "[2023-06-29 00:14:45,593] [INFO] [engine.py:837:_run_pass] Running pass OrtPerfTuning\n",
      "[2023-06-29 00:14:45,596] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:14:47,326] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 0), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:14:58,233] [INFO] [perf_tuning.py:106:tune_onnx_model] Run tuning for: [('provider', 'CPUExecutionProvider'), ('execution_mode', 1), ('ort_opt_level', 99), ('io_bind', False)]\n",
      "[2023-06-29 00:15:17,108] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 196.05226\n",
      "[2023-06-29 00:15:17,109] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 26.61709\n",
      "[2023-06-29 00:15:17,110] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 36.43117\n",
      "[2023-06-29 00:15:17,110] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 28.41241\n",
      "[2023-06-29 00:15:17,110] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 29.891\n",
      "[2023-06-29 00:15:17,111] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 33.73918\n",
      "[2023-06-29 00:15:17,111] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 33.83653\n",
      "[2023-06-29 00:15:17,111] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 34.48713\n",
      "[2023-06-29 00:15:17,112] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 30.04336\n",
      "[2023-06-29 00:15:17,112] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 197.81958\n",
      "[2023-06-29 00:15:17,113] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 25.34003\n",
      "[2023-06-29 00:15:17,113] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 38.36773\n",
      "[2023-06-29 00:15:17,113] [DEBUG] [perf_tuning.py:112:tune_onnx_model] Tuning result: 27.06558\n",
      "[2023-06-29 00:15:17,114] [INFO] [perf_tuning.py:115:tune_onnx_model] Best result: {'test_name': \"execution_provider_[('CPUExecutionProvider', {})]_session_options_{'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': 12}__io_bind_False\", 'execution_provider': [('CPUExecutionProvider', {})], 'session_options': {'execution_mode': 1, 'graph_optimization_level': 99, 'extra_session_config': None, 'inter_op_num_threads': 1, 'intra_op_num_threads': 12}, 'io_bind': False, 'latency_ms': 25.34003}\n",
      "[2023-06-29 00:15:17,117] [DEBUG] [engine.py:964:_evaluate_model] Evaluating model ...\n",
      "[2023-06-29 00:15:17,117] [DEBUG] [engine.py:703:_prepare_non_local_model] Model path is None, local or string name. No need to prepare\n",
      "[2023-06-29 00:15:30,319] [DEBUG] [engine.py:819:_run_passes] Signal: {'accuracy-accuracy': 0.8455882352941176, 'latency-avg': 24.7194}\n",
      "[2023-06-29 00:15:30,324] [INFO] [footprint.py:167:get_pareto_frontier] pareto frontier points: 5_OrtPerfTuning-4-600614b69719e936ca21efbf07971aec {'accuracy-accuracy': 0.8455882352941176, 'latency-avg': 24.17589}\n",
      "[2023-06-29 00:15:30,324] [INFO] [engine.py:513:run_search] Output all 1 models\n",
      "[2023-06-29 00:15:30,325] [INFO] [engine.py:337:run] No packaging config provided, skip packaging artifacts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import check_search_output, patch_config\n",
    "\n",
    "\n",
    "from olive.workflows import run as olive_run\n",
    "\n",
    "olive_config = patch_config(\"bert_workflow_cpu.json\")\n",
    "footprint = olive_run(olive_config)\n",
    "check_search_output(footprint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=MetricResult(__root__={'accuracy-accuracy': SubMetricResult(value=0.8455882352941176, priority=1, higher_is_better=True), 'latency-avg': SubMetricResult(value=24.17589, priority=2, higher_is_better=False)}) cmp_direction={'accuracy-accuracy': 1, 'latency-avg': -1} is_goals_met=True\n",
      "('value', MetricResult(__root__={'accuracy-accuracy': SubMetricResult(value=0.8455882352941176, priority=1, higher_is_better=True), 'latency-avg': SubMetricResult(value=24.17589, priority=2, higher_is_better=False)}))\n",
      "('cmp_direction', {'accuracy-accuracy': 1, 'latency-avg': -1})\n",
      "('is_goals_met', True)\n"
     ]
    }
   ],
   "source": [
    "footprint\n",
    "#get first item from dict\n",
    "fooott = list(footprint.values())[0] \n",
    "\n",
    "for node in fooott.nodes.values():\n",
    "    print(node.metrics)\n",
    "    for node in node.metrics:\n",
    "        print(node)\n",
    "   # print(type(node.metrics.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olive.engine.footprint import Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = Footprint.from_file(\"models/bert_workflow_cpu/cpu-cpu_pareto_frontier_footprints.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8455882352941176, -24.17589]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_of_interest = ['accuracy-accuracy', 'latency-avg']\n",
    "# gather the metrics from all pareto frontier nodes\n",
    "all_metrics = []\n",
    "# we iterate over the nodes in the pareto frontier\n",
    "for node in pf.nodes.values():\n",
    "    metrics = []\n",
    "    # collecting the metrics of interest\n",
    "    for name in metrics_of_interest:\n",
    "        # (value of metric * direction of comparison)\n",
    "        # now higher is better for all metrics\n",
    "        metrics.append(node.metrics.value[name].value * node.metrics.cmp_direction[name])\n",
    "    all_metrics.append(metrics)\n",
    "# sort the metrics\n",
    "# this sorts it\n",
    "sorted_metrics = sorted(all_metrics, reverse=True)\n",
    "# get best metrics\n",
    "# last one is the best\n",
    "best_metrics = sorted_metrics[0]\n",
    "best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 -20\n",
      "0.8455882352941176 -24.17589\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#open best metrics json\n",
    "with open('best_metrics.json') as f:\n",
    "    data = json.load(f)\n",
    "    print(data[0], data[1])\n",
    "    print(best_metrics[0], best_metrics[1])\n",
    "    if best_metrics[0] > data[0] and best_metrics[1] < data[1]:\n",
    "        best_metrics = data\n",
    "#save best metrics to json\n",
    "with open('best_metrics.json', 'w') as f:\n",
    "    json.dump(best_metrics, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emmanuel-onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
